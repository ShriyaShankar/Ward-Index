{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Adithi\n",
      "[nltk_data]     Satish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics \n",
    "import os\n",
    "import warnings\n",
    "import nltk\n",
    "import string\n",
    "import collections\n",
    "import matplotlib.cm as cm\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "from collections import Counter\n",
    "import random\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from textblob import TextBlob,Word,Blobber\n",
    "import csv\n",
    "\n",
    "nltk.download('stopwords')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# train.csv has the text to be trained\n",
    "# training_set.txt has the trained text as .txt file\n",
    "# trained_dataset.csv has the trained text as .csv file\n",
    "# desc_with_sentiment[] has trained text as list\n",
    "def creating_training_model():\n",
    "    desc_with_sentiment = []\n",
    "    polarity = 0\n",
    "    f= 'train.csv'\n",
    "    with open(f,'r') as train:\n",
    "        rows = csv.reader(train)\n",
    "        for row in rows:\n",
    "            sentence = row[0]\n",
    "            blob = TextBlob(sentence, classifier=train)\n",
    "          #  print(sentence, blob.sentiment)\n",
    "            with open('training_set.txt', 'a+') as training_set:\n",
    "                if blob.sentiment.polarity > 0:\n",
    "                    polarity = (2*blob.sentiment.polarity)-1\n",
    "                    training_set.write(sentence + ',' + str(polarity) + '\\n')\n",
    "                else:\n",
    "                    polarity = 2*blob.sentiment.polarity\n",
    "                    training_set.write(sentence + ',' + str(polarity) + '\\n')\n",
    "                with open('trained_dataset.csv', 'a+', newline='') as file:\n",
    "                    writer = csv.writer(file)\n",
    "                    writer.writerow([sentence, polarity])\n",
    "                desc_with_sentiment.append((sentence, blob.sentiment.polarity))\n",
    "\n",
    "creating_training_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
