{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Adithi\n",
      "[nltk_data]     Satish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import random\n",
    "import nltk\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from textblob import TextBlob,Word,Blobber\n",
    "import csv\n",
    "import GetOldTweets3 as got\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('stopwords')\n",
    "warnings.filterwarnings('ignore')\n",
    "df = pd.read_excel('ninja_reports2.xls',sheet_name='ninja_reports')\n",
    "\n",
    "tweetCriteria = got.manager.TweetCriteria().setQuerySearch('BBMP').setNear('Bengaluru').setMaxTweets(500).setSince('2019-01-01').setUntil('2019-12-31')\n",
    "tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "text_tweets = [tweet.text for tweet in tweets]\n",
    "\n",
    "def add_tweets():\n",
    "    cleaned_tweets = []\n",
    "    for tweet in text_tweets:\n",
    "        cleaned_tweets.append( ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) )\n",
    "    \n",
    "    polarity = 0\n",
    "    rows = cleaned_tweets\n",
    "    for row in rows:\n",
    "        #sentence = row[0]\n",
    "        blob = TextBlob(row)\n",
    "        with open('training_set.txt', 'a+') as training_set:\n",
    "            if blob.sentiment.polarity > 0:\n",
    "                polarity = (2*blob.sentiment.polarity)-1\n",
    "                training_set.write(row + ',' + str(polarity) + '\\n')\n",
    "            else:\n",
    "                polarity = 2*blob.sentiment.polarity\n",
    "                training_set.write(row + ',' + str(polarity) + '\\n')\n",
    "            with open('trained_dataset.csv', 'a+', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([row, polarity])\n",
    "\n",
    "add_tweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
